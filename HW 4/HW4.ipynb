{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# HW 4\n",
        "\n",
        "### Done in collboration between Quentin Phillips and Steven Jia"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8hFDk8pwUfik",
        "outputId": "182556c5-9142-4bb3-e053-1386d0b073b1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: torch-pso in /usr/local/lib/python3.10/dist-packages (1.2.1)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (from torch-pso) (2.2.1+cu121)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch->torch-pso) (3.13.3)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch->torch-pso) (4.10.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch->torch-pso) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch->torch-pso) (3.2.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch->torch-pso) (3.1.3)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch->torch-pso) (2023.6.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch->torch-pso) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch->torch-pso) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch->torch-pso) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /usr/local/lib/python3.10/dist-packages (from torch->torch-pso) (8.9.2.26)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /usr/local/lib/python3.10/dist-packages (from torch->torch-pso) (12.1.3.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /usr/local/lib/python3.10/dist-packages (from torch->torch-pso) (11.0.2.54)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /usr/local/lib/python3.10/dist-packages (from torch->torch-pso) (10.3.2.106)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /usr/local/lib/python3.10/dist-packages (from torch->torch-pso) (11.4.5.107)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /usr/local/lib/python3.10/dist-packages (from torch->torch-pso) (12.1.0.106)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.19.3 in /usr/local/lib/python3.10/dist-packages (from torch->torch-pso) (2.19.3)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch->torch-pso) (12.1.105)\n",
            "Requirement already satisfied: triton==2.2.0 in /usr/local/lib/python3.10/dist-packages (from torch->torch-pso) (2.2.0)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.10/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch->torch-pso) (12.4.127)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch->torch-pso) (2.1.5)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch->torch-pso) (1.3.0)\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torchvision import datasets\n",
        "from torchvision import transforms\n",
        "from torch.utils.data.sampler import SubsetRandomSampler\n",
        "!pip install torch-pso\n",
        "from torch_pso import ParticleSwarmOptimizer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uIMPtmo2Ufim",
        "outputId": "a6bdb05b-ed09-4f3d-876b-200126910f5a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Using cuda device\n"
          ]
        }
      ],
      "source": [
        "# Get gpu, mps or cpu device for training.\n",
        "device = (\n",
        "    \"cuda\"\n",
        "    if torch.cuda.is_available()\n",
        "    else \"mps\"\n",
        "    if torch.backends.mps.is_available()\n",
        "    else \"cpu\"\n",
        ")\n",
        "print(f\"Using {device} device\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mnffehnVUfin",
        "outputId": "aff8d8f1-c0e2-4a55-a5f6-4eda0579b6d9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n"
          ]
        }
      ],
      "source": [
        "def get_train_valid_loader(data_dir,\n",
        "                           batch_size,\n",
        "                           augment,\n",
        "                           random_seed,\n",
        "                           valid_size=0.1,\n",
        "                           shuffle=True):\n",
        "    normalize = transforms.Normalize(\n",
        "        mean=[0.4914, 0.4822, 0.4465],\n",
        "        std=[0.2023, 0.1994, 0.2010],\n",
        "    )\n",
        "\n",
        "    # define transforms\n",
        "    valid_transform = transforms.Compose([\n",
        "            transforms.Resize((128,128)),\n",
        "            transforms.ToTensor(),\n",
        "            normalize,\n",
        "    ])\n",
        "    if augment:\n",
        "        train_transform = transforms.Compose([\n",
        "            transforms.Resize((128,128)),\n",
        "            transforms.RandomCrop(120, padding=4),\n",
        "            transforms.RandomHorizontalFlip(),\n",
        "            transforms.ToTensor(),\n",
        "            normalize,\n",
        "        ])\n",
        "    else:\n",
        "        train_transform = transforms.Compose([\n",
        "            transforms.Resize((227,227)),\n",
        "            transforms.ToTensor(),\n",
        "            normalize,\n",
        "        ])\n",
        "\n",
        "    # load the dataset\n",
        "    train_dataset = datasets.CIFAR10(\n",
        "        root=data_dir, train=True,\n",
        "        download=True, transform=train_transform,\n",
        "    )\n",
        "\n",
        "    valid_dataset = datasets.CIFAR10(\n",
        "        root=data_dir, train=True,\n",
        "        download=True, transform=valid_transform,\n",
        "    )\n",
        "\n",
        "    num_train = len(train_dataset)\n",
        "    indices = list(range(num_train))\n",
        "    split = int(np.floor(valid_size * num_train))\n",
        "\n",
        "    if shuffle:\n",
        "        np.random.seed(random_seed)\n",
        "        np.random.shuffle(indices)\n",
        "\n",
        "    train_idx, valid_idx = indices[split:], indices[:split]\n",
        "    train_sampler = SubsetRandomSampler(train_idx)\n",
        "    valid_sampler = SubsetRandomSampler(valid_idx)\n",
        "\n",
        "    train_loader = torch.utils.data.DataLoader(\n",
        "        train_dataset, batch_size=batch_size, sampler=train_sampler)\n",
        "\n",
        "    valid_loader = torch.utils.data.DataLoader(\n",
        "        valid_dataset, batch_size=batch_size, sampler=valid_sampler)\n",
        "\n",
        "    return (train_loader, valid_loader)\n",
        "\n",
        "\n",
        "def get_test_loader(data_dir,\n",
        "                    batch_size,\n",
        "                    shuffle=True):\n",
        "    normalize = transforms.Normalize(\n",
        "        mean=[0.485, 0.456, 0.406],\n",
        "        std=[0.229, 0.224, 0.225],\n",
        "    )\n",
        "\n",
        "    # define transform\n",
        "    transform = transforms.Compose([\n",
        "        transforms.Resize((128,128)),\n",
        "        transforms.ToTensor(),\n",
        "        normalize,\n",
        "    ])\n",
        "\n",
        "    dataset = datasets.CIFAR10(\n",
        "        root=data_dir, train=False,\n",
        "        download=True, transform=transform,\n",
        "    )\n",
        "\n",
        "    data_loader = torch.utils.data.DataLoader(\n",
        "        dataset, batch_size=batch_size, shuffle=shuffle\n",
        "    )\n",
        "\n",
        "    return data_loader\n",
        "\n",
        "\n",
        "# dataset\n",
        "train_loader, valid_loader = get_train_valid_loader(data_dir = './data',                                      batch_size = 64,\n",
        "                       augment = True,random_seed = 123)\n",
        "\n",
        "test_loader = get_test_loader(data_dir = './data',\n",
        "                              batch_size = 72)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ep3fIopqUfio"
      },
      "outputs": [],
      "source": [
        "class model1(nn.Module):\n",
        "    def __init__(self, num_classes=10):\n",
        "        super(model1, self).__init__()\n",
        "        self.layer1 = nn.Sequential(\n",
        "            nn.Conv2d(3, 96, kernel_size=11, stride=4, padding=0),\n",
        "            nn.BatchNorm2d(96),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(kernel_size = 3, stride = 2))\n",
        "        self.layer2 = nn.Sequential(\n",
        "            nn.Conv2d(96, 256, kernel_size=5, stride=1, padding=2),\n",
        "            nn.BatchNorm2d(256),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(kernel_size = 3, stride = 2))\n",
        "        self.layer3 = nn.Sequential(\n",
        "            nn.Conv2d(256, 384, kernel_size=3, stride=1, padding=1),\n",
        "            nn.BatchNorm2d(384),\n",
        "            nn.ReLU())\n",
        "        self.layer4 = nn.Sequential(\n",
        "            nn.Conv2d(384, 384, kernel_size=3, stride=1, padding=1),\n",
        "            nn.BatchNorm2d(384),\n",
        "            nn.ReLU())\n",
        "        self.layer5 = nn.Sequential(\n",
        "            nn.Conv2d(384, 256, kernel_size=3, stride=1, padding=1),\n",
        "            nn.BatchNorm2d(256),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(kernel_size = 3, stride = 2))\n",
        "        self.fc = nn.Sequential(\n",
        "            nn.Dropout(0.5),\n",
        "            nn.Linear(1024, 4096),\n",
        "            nn.ReLU())\n",
        "        self.fc1 = nn.Sequential(\n",
        "            nn.Dropout(0.5),\n",
        "            nn.Linear(4096, 4096),\n",
        "            nn.ReLU())\n",
        "        self.fc2= nn.Sequential(\n",
        "            nn.Linear(4096, num_classes))\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = self.layer1(x)\n",
        "        out = self.layer2(out)\n",
        "        out = self.layer3(out)\n",
        "        out = self.layer4(out)\n",
        "        out = self.layer5(out)\n",
        "        out = out.reshape(out.size(0), -1)\n",
        "        out = self.fc(out)\n",
        "        out = self.fc1(out)\n",
        "        out = self.fc2(out)\n",
        "        return out"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iCOahi3MTsve"
      },
      "outputs": [],
      "source": [
        "def NNRun(model, optimizer, criterion, num_epochs = 20):\n",
        "  for epoch in range(num_epochs):\n",
        "      for i, (images, labels) in enumerate(train_loader):\n",
        "          # Move tensors to the configured device\n",
        "          images = images.to(device)\n",
        "          labels = labels.to(device)\n",
        "\n",
        "          # Forward pass\n",
        "          outputs = model(images)\n",
        "          loss = criterion(outputs, labels)\n",
        "\n",
        "          # Backward and optimize\n",
        "          optimizer.zero_grad()\n",
        "          loss.backward()\n",
        "          optimizer.step()\n",
        "\n",
        "  with torch.no_grad():\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    for images, labels in test_loader:\n",
        "        images = images.to(device)\n",
        "        labels = labels.to(device)\n",
        "        outputs = model(images)\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "        del images, labels, outputs\n",
        "\n",
        "    return correct / total"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Xd4f7J4EPMlZ"
      },
      "outputs": [],
      "source": [
        "# PSO algorithm\n",
        "\n",
        "def particle_swarm_optimization(num_dimensions, num_particles, max_iter,i_min=-10,i_max=10,bounds=None,w=0.5,c1=0.25,c2=0.75):\n",
        "    # Initialize the particles\n",
        "    # This creates a data structure such as a dictionary\n",
        "\n",
        "    if bounds is None:\n",
        "        particles = [({'position': [np.random.uniform(i_min, i_max) for _ in range(num_dimensions)],\n",
        "                    'velocity': [np.random.uniform(-1, 1) for _ in range(num_dimensions)],\n",
        "                    'pbest': 0,\n",
        "                    'pbest_position': [0, 0]})\n",
        "                    for _ in range(num_particles)]\n",
        "    else:\n",
        "        particles = [({'position': [np.random.uniform(bounds[i][0], bounds[i][1]) for i in range(num_dimensions)],\n",
        "                    'velocity': [np.random.uniform(-1, 1) for _ in range(num_dimensions)],\n",
        "                    'pbest': 0,\n",
        "                    'pbest_position': [0, 0]})\n",
        "                    for _ in range(num_particles)]\n",
        "\n",
        "    # Initialize global best\n",
        "    gbest_value = 0\n",
        "    gbest_position = [0, 0]\n",
        "\n",
        "    for _ in range(max_iter):\n",
        "        for particle in particles:\n",
        "            position = particle['position']\n",
        "            velocity = particle['velocity']\n",
        "\n",
        "            # Calculate the current value\n",
        "            model =  model1(num_classes=10).to(device)\n",
        "            optimizer = torch.optim.SGD(model.parameters(), lr=position[0], weight_decay=position[1])\n",
        "            criterion = nn.CrossEntropyLoss()\n",
        "            current_value = NNRun(model, optimizer, criterion)\n",
        "\n",
        "            print(f\"position: {position} cr: {current_value} pbest: {particle['pbest']} gbest: {gbest_value}\")\n",
        "\n",
        "            # Update personal best\n",
        "            if current_value > particle['pbest']:\n",
        "                particle['pbest'] = current_value\n",
        "                particle['pbest_position'] = position.copy()\n",
        "                print(f\" if statement part - position: {position} cr: {current_value}\")\n",
        "\n",
        "            # Update global best\n",
        "            if current_value > gbest_value:\n",
        "                gbest_value = current_value\n",
        "                gbest_position = position.copy()\n",
        "                print(gbest_value)\n",
        "\n",
        "            # Update particle's velocity and position\n",
        "            for i in range(num_dimensions):\n",
        "                r1, r2 = np.random.uniform(), np.random.uniform()\n",
        "                velocity[i] = w * velocity[i] + c1*r1 * (particle['pbest_position'][i] - position[i]) + c2*r2 * (gbest_position[i] - position[i])\n",
        "                position[i] += velocity[i]\n",
        "                # legalize the values to the provided bounds\n",
        "                if bounds is not None:\n",
        "                    position[i] = np.clip(position[i],bounds[i][0],bounds[i][1])\n",
        "\n",
        "    return gbest_position, gbest_value"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kJ0u0rXvRXbv",
        "outputId": "47977a4f-b0f4-4b73-e203-5b69694dcb27"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "position: [0.2134304219883172, 0.007092218140461653] cr: 0.3222 pbest: 0 gbest: 0\n",
            " if statement part - position: [0.2134304219883172, 0.007092218140461653] cr: 0.3222\n",
            "0.3222\n",
            "position: [0.12558547816999002, 0.008697257626510899] cr: 0.5342 pbest: 0 gbest: 0.3222\n",
            " if statement part - position: [0.12558547816999002, 0.008697257626510899] cr: 0.5342\n",
            "0.5342\n",
            "position: [0.13998795433743189, 0.00010326280096908705] cr: 0.8409 pbest: 0 gbest: 0.5342\n",
            " if statement part - position: [0.13998795433743189, 0.00010326280096908705] cr: 0.8409\n",
            "0.8409\n",
            "position: [0.20640656424164378, 0.0029712282306877166] cr: 0.597 pbest: 0 gbest: 0.8409\n",
            " if statement part - position: [0.20640656424164378, 0.0029712282306877166] cr: 0.597\n",
            "position: [0.2832350070623105, 0.001959581477573873] cr: 0.3378 pbest: 0 gbest: 0.8409\n",
            " if statement part - position: [0.2832350070623105, 0.001959581477573873] cr: 0.3378\n",
            "position: [0.1777089116931845, 0.0021284828449193846] cr: 0.477 pbest: 0 gbest: 0.8409\n",
            " if statement part - position: [0.1777089116931845, 0.0021284828449193846] cr: 0.477\n",
            "position: [0.15152023826107056, 0.0020669707185965443] cr: 0.7284 pbest: 0 gbest: 0.8409\n",
            " if statement part - position: [0.15152023826107056, 0.0020669707185965443] cr: 0.7284\n",
            "position: [0.3, 0.01] cr: 0.2855 pbest: 0.3222 gbest: 0.8409\n",
            "position: [0.1, 0.0001] cr: 0.8146 pbest: 0.5342 gbest: 0.8409\n",
            " if statement part - position: [0.1, 0.0001] cr: 0.8146\n",
            "position: [0.3, 0.01] cr: 0.2304 pbest: 0.8409 gbest: 0.8409\n",
            "position: [0.1, 0.01] cr: 0.4852 pbest: 0.597 gbest: 0.8409\n",
            "position: [0.1, 0.0001] cr: 0.8183 pbest: 0.3378 gbest: 0.8409\n",
            " if statement part - position: [0.1, 0.0001] cr: 0.8183\n",
            "position: [0.1, 0.0001] cr: 0.8378 pbest: 0.477 gbest: 0.8409\n",
            " if statement part - position: [0.1, 0.0001] cr: 0.8378\n",
            "position: [0.1, 0.0001] cr: 0.7967 pbest: 0.7284 gbest: 0.8409\n",
            " if statement part - position: [0.1, 0.0001] cr: 0.7967\n",
            "position: [0.3, 0.01] cr: 0.1916 pbest: 0.3222 gbest: 0.8409\n",
            "position: [0.1, 0.0001] cr: 0.8155 pbest: 0.8146 gbest: 0.8409\n",
            " if statement part - position: [0.1, 0.0001] cr: 0.8155\n",
            "position: [0.2859366564069254, 0.01] cr: 0.4604 pbest: 0.8409 gbest: 0.8409\n",
            "position: [0.1, 0.01] cr: 0.5301 pbest: 0.597 gbest: 0.8409\n",
            "position: [0.1, 0.0001] cr: 0.815 pbest: 0.8183 gbest: 0.8409\n",
            "position: [0.1, 0.0001] cr: 0.8184 pbest: 0.8378 gbest: 0.8409\n",
            "position: [0.1, 0.0001] cr: 0.7922 pbest: 0.7967 gbest: 0.8409\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "([0.13998795433743189, 0.00010326280096908705], 0.8409)"
            ]
          },
          "execution_count": 34,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "particle_swarm_optimization(num_dimensions=2, num_particles=7, max_iter=3, bounds=[(0.1, 0.3), (0.0001, 0.01)])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TmASfMcHaZqE"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "V100",
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
